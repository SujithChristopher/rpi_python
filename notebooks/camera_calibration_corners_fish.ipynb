{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "import numpy as np\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pth = os.path.dirname(os.getcwd())\n",
    "_parent_folder = \"data\"\n",
    "_calib_folder_name = \"calib_1200_400_af\"\n",
    "\n",
    "_webcam_calib_folder = os.path.join(\n",
    "    _pth, _parent_folder, \"calibration\", _calib_folder_name\n",
    ")\n",
    "_webcam_calib_video = os.path.join(_webcam_calib_folder, \"webcam_color.msgpack\")\n",
    "_webcam_calib_folder = os.path.join(_webcam_calib_folder)\n",
    "_webcam_calib_pth = os.path.join(_webcam_calib_folder, \"webcam_calibration.msgpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_ORIGINAL)\n",
    "detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "markerLength = 0.05\n",
    "markerSeperation = 0.01\n",
    "\n",
    "board = aruco.GridBoard(\n",
    "    size=[1, 1],\n",
    "    markerLength=markerLength,\n",
    "    markerSeparation=markerSeperation,\n",
    "    dictionary=ARUCO_DICT,\n",
    ")\n",
    "_video_pth = _webcam_calib_video\n",
    "_video_file = open(_video_pth, \"rb\")\n",
    "_video_data = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "_video_length = 0\n",
    "\n",
    "for _frame in _video_data:\n",
    "    _video_length += 1\n",
    "\n",
    "_video_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "_video_pth = _webcam_calib_video\n",
    "_video_file = open(_video_pth, \"rb\")\n",
    "_video_data = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "\n",
    "marker_corners = []\n",
    "marker_ids = []\n",
    "counter = 0\n",
    "rnd = np.random.choice(_video_length, 150, replace=False)\n",
    "for idx, data_points in enumerate(_video_data):\n",
    "    corners, ids = data_points\n",
    "\n",
    "    marker_corners.append(corners)\n",
    "    marker_ids.append(ids)\n",
    "    counter += 1\n",
    "\n",
    "_video_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4, 1, 3)).shape\n",
    "rnd = np.random.choice(_video_length, 50, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_points = []\n",
    "processed_object_points = []\n",
    "for _f in range(len(marker_corners)):\n",
    "    if _f in rnd:\n",
    "        current_object_points, current_image_points = board.matchImagePoints(\n",
    "            marker_corners[_f], marker_ids[_f]\n",
    "        )\n",
    "        try:\n",
    "            if current_object_points.any() and current_image_points.any():\n",
    "                if current_object_points.shape == np.zeros((4, 1, 3)).shape:\n",
    "                    new_matrix = np.zeros((4, 1, 3), dtype=np.float32)\n",
    "                    new_matrix[:, :, :2] = current_image_points\n",
    "                    processed_image_points.append(new_matrix)\n",
    "                    processed_object_points.append(current_object_points)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDeng = False\n",
    "cameraNumber = 4\n",
    "useFisheye = True\n",
    "\n",
    "patternSize = (6,4)\n",
    "squareSize = 50\n",
    "imgSize = (1200,480)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "def construct3DPoints(patternSize,squareSize):\n",
    "    X = np.zeros((patternSize[0]*patternSize[1],3), np.float32)\n",
    "    X[:,:2] = np.mgrid[0:patternSize[0],0:patternSize[1]].T.reshape(-1,2)\n",
    "    X = X * squareSize\n",
    "    return X\n",
    "\n",
    "boardPoints = construct3DPoints(patternSize,squareSize)\n",
    "worldPoints = []\n",
    "imagePoints = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boardPoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistortFisheye(imgpath,K,D,DIM,axis,method,scale,corners):\n",
    "    img = cv2.imread(imgpath)\n",
    "    '''\n",
    "    new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K, D, DIM, np.eye(3), balance=0)\n",
    "    new_K = K.copy()\n",
    "    new_K[0,0]=K[0,0]*scale\n",
    "    new_K[1,1]=K[1,1]*scale\n",
    "    '''\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    fx = K[0,0]\n",
    "    fy = K[1,1]\n",
    "    cx = K[0,2]\n",
    "    cy = K[1,2]\n",
    "    undCorners_norm = cv2.fisheye.undistortPoints(corners, K, D)\n",
    "    undCorners_norm = undCorners_norm.reshape(-1,2)\n",
    "    undistCorners = np.zeros_like(undCorners_norm)\n",
    "    for i, (x, y) in enumerate(undCorners_norm):\n",
    "        px = x*fx + cx\n",
    "        py = y*fy + cy\n",
    "        undistCorners[i,0] = px\n",
    "        undistCorners[i,1] = py    \n",
    "    cv2.drawChessboardCorners(undistorted_img, patternSize, undistCorners, _)\n",
    "\n",
    "    axs[axis].imshow(undistorted_img[:,:,::-1])\n",
    "    axs[axis].axis('off')\n",
    "    axs[axis].set_title('undistort '+method)\n",
    "    #cv2.imwrite('undistort'+method+'.png', undistorted_img)\n",
    "\n",
    "    return corners,undistCorners\n",
    "\n",
    "def undistortPinhole(imgpath,K,D,DIM,axis,method,corners):\n",
    "    img = cv2.imread(imgpath)\n",
    "    \n",
    "    new_K, roi = cv2.getOptimalNewCameraMatrix(K, D, DIM, 1, DIM)\n",
    "    undistorted_img = cv2.undistort(img,K,D, None, new_K)  \n",
    "\n",
    "    undCorners_norm = cv2.undistortPoints(corners, K, D).reshape(-1,2)\n",
    "    # remove normalization\n",
    "    fx = new_K[0,0]\n",
    "    fy = new_K[1,1]\n",
    "    cx = new_K[0,2]\n",
    "    cy = new_K[1,2]\n",
    "    undistCorners = np.zeros_like(undCorners_norm)\n",
    "    for i, (x, y) in enumerate(undCorners_norm):\n",
    "        px = x*fx + cx\n",
    "        py = y*fy + cy\n",
    "        undistCorners[i,0] = px\n",
    "        undistCorners[i,1] = py    \n",
    "    cv2.drawChessboardCorners(undistorted_img, patternSize, undistCorners, _)\n",
    "    axs[axis].imshow(undistorted_img[:,:,::-1])\n",
    "    axs[axis].axis('off')\n",
    "    axs[axis].set_title('undistorted '+method)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "_video_pth = _webcam_calib_video\n",
    "_video_file = open(_video_pth, \"rb\")\n",
    "_video_data = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "\n",
    "marker_corners = []\n",
    "marker_ids = []\n",
    "counter = 0\n",
    "rnd = np.random.choice(_video_length, 150, replace=False)\n",
    "for idx, data_points in enumerate(_video_data):\n",
    "    corners, ids = data_points\n",
    "    \n",
    "    if corners is not None:\n",
    "        \n",
    "        if len(corners) == 12:\n",
    "        # cornersRefined = cv2.cornerSubPix(gray, corners, (7,7), (-1,-1), criteria)\n",
    "            imagePoints.append(corners)\n",
    "            worldPoints.append(boardPoints)\n",
    "\n",
    "_video_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fisheye.cpp:754: error: (-215:Assertion failed) imagePoints.type() == CV_32FC2 || imagePoints.type() == CV_64FC2 in function 'cv::fisheye::calibrate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     flagsCalib \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfisheye\u001b[38;5;241m.\u001b[39mCALIB_RECOMPUTE_EXTRINSIC\u001b[38;5;241m+\u001b[39mcv2\u001b[38;5;241m.\u001b[39mfisheye\u001b[38;5;241m.\u001b[39mCALIB_FIX_SKEW\u001b[38;5;241m+\u001b[39mcv2\u001b[38;5;241m.\u001b[39mfisheye\u001b[38;5;241m.\u001b[39mCALIB_CHECK_COND\n\u001b[0;32m      3\u001b[0m     calibrateCriteria \u001b[38;5;241m=\u001b[39m (cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS\u001b[38;5;241m+\u001b[39mcv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_MAX_ITER,\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1e-12\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     ret, cameraMatrix, k, R, t \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfisheye\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworldPoints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagePoints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflagsCalib\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibrateCriteria\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     flagsCalib \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCALIB_RATIONAL_MODEL\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fisheye.cpp:754: error: (-215:Assertion failed) imagePoints.type() == CV_32FC2 || imagePoints.type() == CV_64FC2 in function 'cv::fisheye::calibrate'\n"
     ]
    }
   ],
   "source": [
    "if useFisheye:\n",
    "    flagsCalib = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC+cv2.fisheye.CALIB_FIX_SKEW+cv2.fisheye.CALIB_CHECK_COND\n",
    "    calibrateCriteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER,30, 1e-12)\n",
    "    ret, cameraMatrix, k, R, t = cv2.fisheye.calibrate(np.expand_dims(np.asarray(worldPoints), -2), np.expand_dims(np.asarray(imagePoints), -2), imgSize, None, None,\n",
    "                                                                flags=flagsCalib,criteria=calibrateCriteria)\n",
    "else:\n",
    "    flagsCalib = cv2.CALIB_RATIONAL_MODEL\n",
    "    ret, cameraMatrix, k, rvecs, tvecs = cv2.calibrateCamera(worldPoints, imagePoints, imgSize, None, None,\n",
    "                                                               flags=flagsCalib)\n",
    "\n",
    "# print(\"Using \"+str(counter)+\" of \"+str(len(images))+\" images\")\n",
    "print(\"RMS re-projection error:\", ret)\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix)\n",
    "print(\"Distortion Parameters:\\n\", k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
